{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ea0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing requirments\n",
    "import pandas as pd\n",
    "import ollama\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1269101a",
   "metadata": {},
   "source": [
    "creating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97ca901",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_embeddings(l):\n",
    "    res = ollama.embed(\n",
    "        model=\"qllama/bge-large-en-v1.5:q4_k_m\",\n",
    "        input=l\n",
    "    )\n",
    "\n",
    "    vector = res[\"embeddings\"]\n",
    "    return vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0305c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = \"my name is keyur\"\n",
    "# print(create_embeddings(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9329d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l=[\"hi\",\"by\"]\n",
    "# print(len(create_embeddings(l)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea5531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating embeddings for 01_Introduction to Programming .json\n",
      "creating embeddings for 02_Some Amazing Python Programs .json\n",
      "creating embeddings for 03_Modules and Pip .json\n",
      "creating embeddings for 04_Our First Python Program .json\n",
      "creating embeddings for 05_Comments.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "jsons = os.listdir(\"jsons\")\n",
    "my_dict = []\n",
    "chunk_id =0\n",
    "for json_file in jsons:\n",
    "    with open(f\"jsons/{json_file}\") as f:\n",
    "        content = json.load(f)\n",
    "    print(f\"creating embeddings for {json_file}\")\n",
    "    embeddings =create_embeddings([c['text'] for c in content[\"chunks\"]])\n",
    "    for i,chunk  in enumerate(content[\"chunks\"]):\n",
    "        chunk[\"chunk_id\"] = chunk_id\n",
    "        chunk[\"embeddings\"] = embeddings[i]\n",
    "        chunk_id += 1\n",
    "        my_dict.append(chunk)\n",
    "        \n",
    "    \n",
    "# print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030255c8",
   "metadata": {},
   "source": [
    "saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443fcb3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = pd.DataFrame.from_records(\u001b[43mmy_dict\u001b[49m)\n\u001b[32m      2\u001b[39m df.to_pickle(\u001b[33m\"\u001b[39m\u001b[33mdata.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'my_dict' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame.from_records(my_dict)\n",
    "df.to_pickle(\"data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc03292",
   "metadata": {},
   "source": [
    "pulling top matching chunks for incoming query and introspecting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba6e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data.pkl\")\n",
    "# df = pd.read_csv(\"embed_data.csv\")    #we are not using csv cause it stored embeddings as list hence we didnt want that so were using pkl to store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4beac9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"embeddings\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e18fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1678, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(np.vstack(df['embeddings']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8adc67ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "incoming_query = input(\"enter a query :\")\n",
    "question_embedding = create_embeddings(incoming_query)[0]\n",
    "# print(np.vstack(df['embeddings']).shape)\n",
    "similarities  =cosine_similarity(np.vstack(df['embeddings']),[question_embedding]).flatten()\n",
    "top_results = 5\n",
    "max_idx = similarities.argsort()[::-1][0:top_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf46a1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     number                         title  \\\n",
      "1501     05                      Comments   \n",
      "804      03              Modules and Pip    \n",
      "61       01  Introduction to Programming    \n",
      "1582     05                      Comments   \n",
      "1545     05                      Comments   \n",
      "\n",
      "                                               text  \n",
      "1501                            tun tun tun tun tun  \n",
      "804                                              hi  \n",
      "61                                           Raplet  \n",
      "1582                     from tilde character, like  \n",
      "1545   followed by the character you want to insert  \n"
     ]
    }
   ],
   "source": [
    "new_df  = df.loc[max_idx]\n",
    "print(new_df[[\"number\",\"title\",\"text\"]])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f885ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lecure title:Comments,lecure number:05,lecture text: tun tun tun tun tun,lecture timings:754.0-756.0', 'lecure title:Modules and Pip ,lecure number:03,lecture text: hi,lecture timings:454.0-456.0', 'lecure title:Introduction to Programming ,lecure number:01,lecture text: Raplet,lecture timings:124.0-126.0', 'lecure title:Comments,lecure number:05,lecture text: from tilde character, like,lecture timings:916.0-918.0', 'lecure title:Comments,lecure number:05,lecture text: followed by the character you want to insert,lecture timings:842.0-844.0']\n"
     ]
    }
   ],
   "source": [
    "context_blocks = []\n",
    "for index,item in new_df.iterrows():\n",
    "    context_blocks.append(f'''lecure title:{item[\"title\"]},lecure number:{item[\"number\"]},lecture text:{item[\"text\"]},lecture timings:{item[\"Start\"]}-{item[\"end\"]}''')\n",
    "print(context_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b55f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''You are a teaching assistant.\n",
    "\n",
    "Use ONLY the lecture content below.\n",
    "Follow this STRICT format:\n",
    "\n",
    "Topic:\n",
    "<one line>\n",
    "\n",
    "Lecture details:\n",
    "- Title:\n",
    "- Lecture number:\n",
    "- Video timestamps:\n",
    "\n",
    "Explanation:\n",
    "<short explanation>\n",
    "\n",
    "Learning steps:\n",
    "- Step 1\n",
    "- Step 2\n",
    "\n",
    "Do NOT combine title and lecture number.\n",
    "Do NOT invent names.\n",
    "Do NOT use general programming knowledge.\n",
    "Use ONLY the lecture content provided, even if it seems incomplete.\n",
    "\n",
    "\n",
    "Lecture content:\n",
    "{context_blocks}\n",
    "\n",
    "Question:\n",
    "{incoming_query}\n",
    "\n",
    "\n",
    "'''\n",
    "with open(\"promp.txt\",\"w\") as f:\n",
    "    f.write(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c40193",
   "metadata": {},
   "source": [
    "# getting response from llm\n",
    "now were using llama2.3:3b which is small in size and faster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f4249b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(prompt):\n",
    "    model =ollama.generate(\n",
    "        model=\"llama3.2:3b\",\n",
    "        prompt=prompt,\n",
    "        stream=False\n",
    "    )\n",
    "    response =  model[\"response\"]\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3199374",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = inference(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0129b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.txt\",\"w\") as f:\n",
    "    f.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cfb657",
   "metadata": {},
   "source": [
    "# Now this section is for merged chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a5137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating embeddings for 01_Introduction to Programming .json\n",
      "creating embeddings for 02_Some Amazing Python Programs .json\n",
      "creating embeddings for 03_Modules and Pip .json\n",
      "creating embeddings for 04_Our First Python Program .json\n",
      "creating embeddings for 05_Comments.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "jsons = os.listdir(\"merge_json\")\n",
    "my_dict = []\n",
    "chunk_id =0\n",
    "for json_file in jsons:\n",
    "    with open(f\"merge_json/{json_file}\") as f:\n",
    "        content = json.load(f)\n",
    "    print(f\"creating embeddings for {json_file}\")\n",
    "    embeddings =create_embeddings([c['text'] for c in content[\"chunks\"]])\n",
    "    for i,chunk  in enumerate(content[\"chunks\"]):\n",
    "        chunk[\"chunk_id\"] = chunk_id\n",
    "        chunk[\"embeddings\"] = embeddings[i]\n",
    "        chunk_id += 1\n",
    "        my_dict.append(chunk)\n",
    "        \n",
    "    \n",
    "# print(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "249ed01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame.from_records(my_dict)\n",
    "df.to_pickle(\"merge_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ac8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"merge_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d0de4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "incoming_query = input(\"enter a query :\")\n",
    "question_embedding = create_embeddings(incoming_query)[0]\n",
    "# print(np.vstack(df['embeddings']).shape)\n",
    "similarities  =cosine_similarity(np.vstack(df['embeddings']),[question_embedding]).flatten()\n",
    "top_results = 5\n",
    "max_idx = similarities.argsort()[::-1][0:top_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52498a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    number                         title  \\\n",
      "185     03              Modules and Pip    \n",
      "336     05                      Comments   \n",
      "18      01  Introduction to Programming    \n",
      "66      01  Introduction to Programming    \n",
      "129     03              Modules and Pip    \n",
      "\n",
      "                                                  text  \n",
      "185   in 24 hours  so this video was  trending  so ...  \n",
      "336   if you have not accessed this code yet  then ...  \n",
      "18    Rapple  So here you can see  That my video  Y...  \n",
      "66    Like the video and subscribe the channel  So ...  \n",
      "129   and you will be able to see this video  and a...  \n"
     ]
    }
   ],
   "source": [
    "new_df  = df.loc[max_idx]\n",
    "print(new_df[[\"number\",\"title\",\"text\"]])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13052c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''You are a teaching assistant.\n",
    "\n",
    "Use ONLY the lecture content below.\n",
    "Follow this STRICT format:\n",
    "\n",
    "Topic:\n",
    "<one line>\n",
    "\n",
    "Lecture details:\n",
    "- Title:\n",
    "- Lecture number:\n",
    "- Video timestamps:\n",
    "\n",
    "Explanation:\n",
    "<short explanation>\n",
    "\n",
    "Learning steps:\n",
    "- Step 1\n",
    "- Step 2\n",
    "\n",
    "Do NOT combine title and lecture number.\n",
    "Do NOT invent names.\n",
    "Do NOT use general programming knowledge.\n",
    "Use ONLY the lecture content provided, even if it seems incomplete.\n",
    "\n",
    "\n",
    "Lecture content:\n",
    "{context_blocks}\n",
    "\n",
    "Question:\n",
    "{incoming_query}\n",
    "\n",
    "'''\n",
    "with open(\"merge_promp.txt\",\"w\") as f:\n",
    "    f.write(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "688ed54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(prompt):\n",
    "    model =ollama.generate(\n",
    "        model=\"llama3.2:3b\",\n",
    "        prompt=prompt,\n",
    "        stream=False\n",
    "    )\n",
    "    response =  model[\"response\"]\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9307e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = inference(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3aeb8f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"merge_output.txt\",\"w\") as f:\n",
    "    f.write(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
